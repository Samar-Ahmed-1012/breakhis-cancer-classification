# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Wm8metH8E51M6WewMmB3w8k2vyUCXWi
"""

# --- Install Required Packages ---
!pip install tensorflow matplotlib scikit-learn pandas opencv-python kaggle

# --- Import Libraries ---
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import cv2
import pandas as pd
import zipfile

# Set random seeds for reproducibility
tf.random.set_seed(42)
np.random.seed(42)

# --- Download Dataset from Kaggle ---
def download_kaggle_dataset():
    # Upload your kaggle.json file when prompted
    from google.colab import files
    print("Please upload your kaggle.json file:")
    files.upload()  # This will prompt you to upload kaggle.json

    # Create .kaggle directory and move the file
    !mkdir -p ~/.kaggle
    !mv kaggle.json ~/.kaggle/
    !chmod 600 ~/.kaggle/kaggle.json

    # Download the dataset
    !kaggle datasets download -d ambarish/breakhis

    # Extract the dataset
    with zipfile.ZipFile('breakhis.zip', 'r') as zip_ref:
        zip_ref.extractall('breakhis_dataset')

    print("Dataset downloaded and extracted successfully!")
    !ls breakhis_dataset

# --- Alternative: Direct Download without kaggle.json ---
def download_direct():
    # Download directly (may require accepting competition rules on Kaggle first)
    !wget -O breakhis.zip "https://www.kaggle.com/api/v1/datasets/download/ambarish/breakhis"

    # Extract the dataset
    with zipfile.ZipFile('breakhis.zip', 'r') as zip_ref:
        zip_ref.extractall('breakhis_dataset')

    print("Dataset downloaded and extracted!")

# --- Data loading function (modified for Kaggle dataset structure) ---
def load_breakhis_data(data_dir, img_size=(128, 128), max_samples=500):
    images = []
    labels = []
    benign_count = 0
    malignant_count = 0

    # Kaggle BreakHis structure: data_dir/BreaKHis_v1/histology_slides/breast/
    base_path = os.path.join(data_dir, "BreaKHis_v1", "histology_slides", "breast")

    # Check if the path exists
    if not os.path.exists(base_path):
        print(f"Base path not found: {base_path}")
        print("Available directories:")
        for root, dirs, files in os.walk(data_dir):
            print(f"{root}: {dirs}")
        return np.array(images), np.array(labels)

    # BreakHis directory structure
    for magnification in ["40X", "100X", "200X", "400X"]:
        mag_dir = os.path.join(base_path, magnification)
        if not os.path.exists(mag_dir):
            print(f"Magnification directory not found: {mag_dir}")
            continue

        for class_name in ["benign", "malignant"]:
            class_dir = os.path.join(mag_dir, class_name)
            if not os.path.exists(class_dir):
                print(f"Class directory not found: {class_dir}")
                continue

            class_label = 0 if class_name == "benign" else 1

            # Get all image files
            image_files = [f for f in os.listdir(class_dir)
                          if f.endswith((".png", ".jpg", ".jpeg"))]

            # Limit samples per class
            samples_needed = max_samples // 2
            if class_label == 0:
                samples_to_take = min(samples_needed - benign_count, len(image_files))
            else:
                samples_to_take = min(samples_needed - malignant_count, len(image_files))

            for img_file in image_files[:samples_to_take]:
                img_path = os.path.join(class_dir, img_file)
                try:
                    # Read and preprocess image
                    img = cv2.imread(img_path)
                    if img is None:
                        print(f"Failed to read image: {img_path}")
                        continue

                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                    img = cv2.resize(img, img_size)
                    img = img / 255.0  # Normalize to [0, 1]

                    images.append(img)
                    labels.append(class_label)

                    if class_label == 0:
                        benign_count += 1
                    else:
                        malignant_count += 1

                except Exception as e:
                    print(f"Error loading image {img_path}: {e}")

    print(f"Loaded {len(images)} images: {benign_count} benign, {malignant_count} malignant")

    # Create dataset summary
    df = pd.DataFrame({
        'Class': ['Benign', 'Malignant'],
        'Count': [benign_count, malignant_count]
    })
    print("\nDataset Summary:")
    print(df)

    return np.array(images), np.array(labels)

# --- Keep your existing model functions ---
def create_cnn_model(input_shape=(128, 128, 3)):
    # Your existing CNN model code
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.Flatten(),
        layers.Dense(64, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(1, activation='sigmoid')
    ])

    model.compile(optimizer='adam',
                  loss='binary_crossentropy',
                  metrics=['accuracy'])

    return model

def create_vgg16_model(input_shape=(128, 128, 3)):
    # Your existing VGG16 model code
    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)
    base_model.trainable = False

    model = models.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(1, activation='sigmoid')
    ])

    model.compile(optimizer=Adam(learning_rate=0.0001),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])

    return model

# --- Keep your existing visualization functions ---
def plot_history(history, model_name):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

    ax1.plot(history.history['accuracy'], label='Training Accuracy')
    if 'val_accuracy' in history.history:
        ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')
    ax1.set_title(f'{model_name} - Accuracy')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Accuracy')
    ax1.legend()

    ax2.plot(history.history['loss'], label='Training Loss')
    if 'val_loss' in history.history:
        ax2.plot(history.history['val_loss'], label='Validation Loss')
    ax2.set_title(f'{model_name} - Loss')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Loss')
    ax2.legend()

    plt.tight_layout()
    plt.savefig(f'{model_name}_training_history.png')
    plt.show()

def generate_report(y_true, y_pred, model_name):
    report = classification_report(y_true, y_pred, target_names=['Benign', 'Malignant'])
    cm = confusion_matrix(y_true, y_pred)

    print(f"\n{model_name} Classification Report:")
    print(report)
    print(f"Confusion Matrix:\n{cm}")

    return report, cm

def create_evaluation_report(cnn_acc, vgg_acc, cnn_report, vgg_report, cnn_cm, vgg_cm):
    report_text = f"""
    CANCER DETECTION EVALUATION REPORT
    ==================================

    Dataset: BreakHis Histopathological Breast Cancer Dataset
    Source: Kaggle (ambarish/breakhis)
    Samples: 500 images (balanced classes)
    Image Size: 128x128 pixels
    Validation Split: 80% training, 20% testing

    MODEL PERFORMANCE SUMMARY
    -------------------------
    Simple CNN Model:
    - Test Accuracy: {cnn_acc:.4f}

    VGG16 Transfer Learning:
    - Test Accuracy: {vgg_acc:.4f}

    DETAILED CLASSIFICATION REPORTS
    -------------------------------
    CNN Model:
    {cnn_report}

    Confusion Matrix:
    {cnn_cm}

    VGG16 Model:
    {vgg_report}

    Confusion Matrix:
    {vgg_cm}
    """

    with open("cancer_detection_evaluation_report.txt", "w") as f:
        f.write(report_text)

    print("Evaluation report saved!")

# --- Main Execution ---
def main():
    print("Setting up Kaggle dataset in Google Colab...")

    # Download the dataset
    try:
        download_direct()  # Try direct download first
    except:
        print("Direct download failed, trying with kaggle.json...")
        download_kaggle_dataset()

    # Set the data directory path
    data_dir = "breakhis_dataset"

    print(f"Loading data from: {data_dir}")

    # Load and preprocess data
    X, y = load_breakhis_data(data_dir, max_samples=500)

    if len(X) == 0:
        print("No images loaded! Check the dataset path and structure.")
        return

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    print(f"Training set: {X_train.shape[0]} images")
    print(f"Test set: {X_test.shape[0]} images")

    # Create and train models
    print("\nTraining simple CNN...")
    cnn_model = create_cnn_model()
    cnn_history = cnn_model.fit(
        X_train, y_train,
        epochs=10,
        batch_size=32,
        validation_data=(X_test, y_test),
        verbose=1
    )

    print("\nTraining VGG16 model...")
    vgg_model = create_vgg16_model()
    vgg_history = vgg_model.fit(
        X_train, y_train,
        epochs=10,
        batch_size=32,
        validation_data=(X_test, y_test),
        verbose=1
    )

    # Evaluate models
    cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test, y_test, verbose=0)
    vgg_loss, vgg_accuracy = vgg_model.evaluate(X_test, y_test, verbose=0)

    print(f"\nCNN Test Accuracy: {cnn_accuracy:.4f}")
    print(f"VGG16 Test Accuracy: {vgg_accuracy:.4f}")

    # Generate predictions and reports
    cnn_preds = (cnn_model.predict(X_test) > 0.5).astype("int32")
    vgg_preds = (vgg_model.predict(X_test) > 0.5).astype("int32")

    cnn_report, cnn_cm = generate_report(y_test, cnn_preds, "CNN")
    vgg_report, vgg_cm = generate_report(y_test, vgg_preds, "VGG16")

    # Plot training history
    plot_history(cnn_history, "CNN")
    plot_history(vgg_history, "VGG16")

    # Create evaluation report
    create_evaluation_report(cnn_accuracy, vgg_accuracy, cnn_report, vgg_report, cnn_cm, vgg_cm)

# Run the main function
if __name__ == "__main__":
    main()